{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e7b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41270f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Detection and Face Mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13aa31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare face_detection as a global variable\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ed6549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Video Validation Toolkit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4ec341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen width and height\n",
    "screen_width = window.winfo_screenwidth()\n",
    "screen_height = window.winfo_screenheight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8482163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimensions for the button and center it on the screen\n",
    "button_width = 200\n",
    "button_height = 50\n",
    "x_position = (screen_width - button_width) / 2\n",
    "y_position = (screen_height - button_height) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f5de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to browse for a video file\n",
    "def browse_video():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4\")])\n",
    "    validate_video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af463ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to copy accepted video to a separate folder\n",
    "def copy_accepted_video(video_path):\n",
    "    # Define the name of the directory to store accepted videos\n",
    "    accepted_videos_directory = \"AcceptedVideos\"  # You can change this to your desired directory name\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(accepted_videos_directory, exist_ok=True)\n",
    "    \n",
    "    # Get the filename from the full video path\n",
    "    _, video_filename = os.path.split(video_path)\n",
    "    \n",
    "    # Construct the destination path for the accepted video in the specified directory\n",
    "    destination_path = os.path.join(accepted_videos_directory, video_filename)\n",
    "    \n",
    "    # Copy the video file to the accepted videos directory\n",
    "    shutil.copy(video_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c524b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw landmarks on the face and validate lip visibility\n",
    "def validate_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Use MoviePy to get the video frame rate\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    frame_rate = video_clip.fps\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate the aspect ratio of the video frame\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        frame_aspect_ratio = frame_width / frame_height\n",
    "\n",
    "        # Calculate the maximum dimensions that fit within the screen\n",
    "        max_width = screen_width\n",
    "        max_height = int(max_width / frame_aspect_ratio)\n",
    "\n",
    "        # If the calculated height is too large, use the screen height as the limit\n",
    "        if max_height > screen_height:\n",
    "            max_height = screen_height\n",
    "            max_width = int(max_height * frame_aspect_ratio)\n",
    "\n",
    "        # Resize the frame to fit within the screen dimensions\n",
    "        frame = cv2.resize(frame, (max_width, max_height))\n",
    "\n",
    "        # Convert the frame to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces\n",
    "        results = face_detection.process(frame_rgb)\n",
    "\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                # Get the exact bounding box dimensions\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                h, w, c = frame.shape\n",
    "                x, y, width, height = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
    "\n",
    "                if width > 0 and height > 0:\n",
    "                    # Draw a bounding box around the face\n",
    "                    cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "                # Detect facial landmarks\n",
    "                landmarks = face_mesh.process(frame_rgb)\n",
    "\n",
    "                if landmarks.multi_face_landmarks:\n",
    "                    for face_landmarks in landmarks.multi_face_landmarks:\n",
    "                        # Draw facial landmarks (lips, eyes, nose)\n",
    "                        mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                                                 landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1))\n",
    "\n",
    "                    # You can access specific lip landmarks here\n",
    "                    # For example, landmark 13 is the upper lip center, and landmark 14 is the lower lip center\n",
    "                    upper_lip = face_landmarks.landmark[13]\n",
    "                    lower_lip = face_landmarks.landmark[14]\n",
    "\n",
    "                    # You can add validation logic for lip visibility here\n",
    "                    if upper_lip and lower_lip:\n",
    "                        if frame_rate == 30:\n",
    "                            validation_result.config(text=\"Accepted (Frontal Face & Visible Lips & 30 FPS)\")\n",
    "                            copy_accepted_video(video_path)  # Copy the accepted video\n",
    "                        elif frame_rate == 25:\n",
    "                            validation_result.config(text=\"Accepted (Frontal Face & Visible Lips & 25 FPS)\")\n",
    "                            copy_accepted_video(video_path)  # Copy the accepted video\n",
    "                        else:\n",
    "                            validation_result.config(text=\"Rejected (Not 25 or 30 FPS)\")\n",
    "                    else:\n",
    "                        validation_result.config(text=\"Rejected (No Visible Lips)\")\n",
    "                else:\n",
    "                    validation_result.config(text=\"Rejected (No Frontal Face)\")\n",
    "\n",
    "        # Display the video frame\n",
    "        cv2.imshow(\"Video Validation\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f245842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the background image\n",
    "background_image = tk.PhotoImage(file=\"pexels-lukas-317356.png\")  # Specify the path to your background image\n",
    "\n",
    "# Create a Canvas widget with the same dimensions as the image\n",
    "canvas = tk.Canvas(window, width=background_image.width(), height=background_image.height())\n",
    "canvas.create_image(0, 0, anchor=tk.NW, image=background_image)\n",
    "canvas.pack()\n",
    "\n",
    "background_label = tk.Label(window, image=background_image)\n",
    "background_label.place(relwidth=1, relheight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dhira\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\dhira\\AppData\\Local\\Temp\\ipykernel_20020\\1219254992.py\", line 4, in browse_video\n",
      "    validate_video(file_path)\n",
      "  File \"C:\\Users\\dhira\\AppData\\Local\\Temp\\ipykernel_20020\\2359464949.py\", line 6, in validate_video\n",
      "    video_clip = VideoFileClip(video_path)\n",
      "  File \"C:\\Users\\dhira\\anaconda3\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py\", line 88, in __init__\n",
      "    self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt,\n",
      "  File \"C:\\Users\\dhira\\anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\", line 35, in __init__\n",
      "    infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n",
      "  File \"C:\\Users\\dhira\\anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\", line 270, in ffmpeg_parse_infos\n",
      "    raise IOError((\"MoviePy error: the file %s could not be found!\\n\"\n",
      "OSError: MoviePy error: the file  could not be found!\n",
      "Please check that you entered the correct path.\n"
     ]
    }
   ],
   "source": [
    "# Create GUI elements\n",
    "browse_button = tk.Button(window, text=\"Browse Video\", font=(\"Helvetica\", 20), width=20, height=2, bg=\"lightblue\", command=browse_video)\n",
    "validation_result = tk.Label(window, text=\"Validation Result: \", font=(\"Helvetica\", 20), bg=\"lightblue\")\n",
    "\n",
    "# Layout the GUI elements\n",
    "browse_button.place(x=x_position, y=y_position)\n",
    "validation_result.place(x=x_position, y=y_position + button_height + 90)  # Adjust the vertical position of the label\n",
    "\n",
    "# Layout the GUI elements\n",
    "#browse_button.place(x=x_position, y=y_position)\n",
    "#validation_result.pack()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e541883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd6cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
